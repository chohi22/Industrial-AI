{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-11T00:04:00.069315Z",
     "start_time": "2025-05-11T00:03:55.110210Z"
    }
   },
   "source": [
    "# 뉴스 요약 데이터셑 불러오기\n",
    "\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "\n",
    "news = load_dataset(\"argilla/news-summary\", split=\"test\")\n",
    "df = news.to_pandas().sample(5000, random_state=42)[[\"text\", \"prediction\"]]\n",
    "df[\"text\"] = \"summarize: \" + df[\"text\"]\n",
    "df[\"prediction\"] = df[\"prediction\"].map(lambda x: x[0][\"text\"])\n",
    "train, valid, test = np.split(df.sample(frac=1, random_state=42), [int(.6*len(df)), int(.8*len(df))])\n",
    "\n",
    "print(f\"Source News: {train.text.values[0]}\")\n",
    "print(f\"Target Summary: {train.prediction.iloc[0]}\")\n",
    "\n",
    "print(f\"Training Data Size : {len(train)}\")\n",
    "print(f\"Validation Data Size : {len(valid)}\")\n",
    "print(f\"Testing Data Size : {len(test)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source News: summarize: DANANG, Vietnam (Reuters) - Russian President Vladimir Putin said on Saturday he had a normal dialogue with U.S. leader Donald Trump at a summit in Vietnam, and described Trump as civil, well-educated, and comfortable to deal with. Putin said that a mooted bilateral sit-down meeting with Trump did not happen at the Asia-Pacific Economic Cooperation summit, citing scheduling issues on both sides and unspecified protocol issues. Putin, at a briefing for reporters at the end of the summit, said there was still a need for further U.S.-Russia contacts, both at the level of heads of state and their officials, to discuss issues including security and economic development.   \n",
      "Target Summary: Putin says had useful interaction with Trump at Vietnam summit\n",
      "Training Data Size : 3000\n",
      "Validation Data Size : 1000\n",
      "Testing Data Size : 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chohi/PythonProject5/.venv/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T00:04:10.552704Z",
     "start_time": "2025-05-11T00:04:00.117646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 뉴스 요약 데이터세트 전처리\n",
    "\n",
    "import torch\n",
    "from transformers import T5Tokenizer\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import RandomSampler, SequentialSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def make_dataset(data, tokenizer, device):\n",
    "    source = tokenizer(\n",
    "        text=data.text.tolist(),\n",
    "        padding=\"max_length\",\n",
    "        max_length=128,\n",
    "        pad_to_max_length=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    target = tokenizer(\n",
    "        text=data.prediction.tolist(),\n",
    "        padding=\"max_length\",\n",
    "        max_length=128,\n",
    "        pad_to_max_length=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    source_ids = source[\"input_ids\"].squeeze().to(device)\n",
    "    source_mask = source[\"attention_mask\"].squeeze().to(device)\n",
    "    target_ids = target[\"input_ids\"].squeeze().to(device)\n",
    "    target_mask = target[\"attention_mask\"].squeeze().to(device)\n",
    "    return TensorDataset(source_ids, source_mask, target_ids, target_mask)\n",
    "\n",
    "def get_datalodader(dataset, sampler, batch_size):\n",
    "    data_sampler = sampler(dataset)\n",
    "    dataloader = DataLoader(dataset, sampler=data_sampler, batch_size=batch_size)\n",
    "    return dataloader\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 8\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"t5-base\"\n",
    ")\n",
    "\n",
    "\n",
    "train_dataset = make_dataset(train, tokenizer, device)\n",
    "train_dataloader = get_datalodader(train_dataset, RandomSampler, batch_size)\n",
    "\n",
    "valid_dataset = make_dataset(valid, tokenizer, device)\n",
    "valid_dataloader = get_datalodader(valid_dataset, SequentialSampler, batch_size)\n",
    "\n",
    "test_dataset = make_dataset(test, tokenizer, device)\n",
    "test_dataloader = get_datalodader(test_dataset, SequentialSampler, batch_size)\n",
    "\n",
    "print(next(iter(train_dataloader)))\n",
    "print(tokenizer.convert_ids_to_tokens(21603))\n",
    "print(tokenizer.convert_ids_to_tokens(10))"
   ],
   "id": "a4b21aed68ff67c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[21603,    10,    41,  ...,     9,  2493,     1],\n",
      "        [21603,    10,   549,  ...,     6,   974,     1],\n",
      "        [21603,    10,   549,  ...,  1041,   224,     1],\n",
      "        ...,\n",
      "        [21603,    10, 24586,  ...,     0,     0,     0],\n",
      "        [21603,    10,     3,  ..., 27409,     6,     1],\n",
      "        [21603,    10,  7109,  ...,     0,     0,     0]], device='cuda:0'), tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), tensor([[   86,  6019,    12,  ...,     0,     0,     0],\n",
      "        [20792, 21077,   283,  ...,     0,     0,     0],\n",
      "        [24463,    10,  4534,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 9995, 24326,     7,  ...,     0,     0,     0],\n",
      "        [21409,  8263,  2493,  ...,     0,     0,     0],\n",
      "        [ 4263, 19791,   342,  ...,     0,     0,     0]], device='cuda:0'), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')]\n",
      "▁summarize\n",
      ":\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T00:04:21.478189Z",
     "start_time": "2025-05-11T00:04:10.624488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# T5 모델 선언\n",
    "from torch import optim\n",
    "from transformers import T5ForConditionalGeneration\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"t5-base\"\n",
    ").to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5, eps=1e-8)"
   ],
   "id": "8f6a4f90d3302e1",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T00:04:21.504683Z",
     "start_time": "2025-05-11T00:04:21.501103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#  모델 구조 출력\n",
    "for main_name, main_module in model.named_children():\n",
    "    print(main_name)\n",
    "    for sub_name, sub_module in main_module.named_children():\n",
    "        print(\"└\", sub_name)\n",
    "        for ssub_name, ssub_module in sub_module.named_children():\n",
    "            print(\"│  └\", ssub_name)\n",
    "            for sssub_name, sssub_module in ssub_module.named_children():\n",
    "                print(\"│  │  └\", sssub_name)"
   ],
   "id": "1ec7236b8e017f41",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared\n",
      "encoder\n",
      "└ embed_tokens\n",
      "└ block\n",
      "│  └ 0\n",
      "│  │  └ layer\n",
      "│  └ 1\n",
      "│  │  └ layer\n",
      "│  └ 2\n",
      "│  │  └ layer\n",
      "│  └ 3\n",
      "│  │  └ layer\n",
      "│  └ 4\n",
      "│  │  └ layer\n",
      "│  └ 5\n",
      "│  │  └ layer\n",
      "│  └ 6\n",
      "│  │  └ layer\n",
      "│  └ 7\n",
      "│  │  └ layer\n",
      "│  └ 8\n",
      "│  │  └ layer\n",
      "│  └ 9\n",
      "│  │  └ layer\n",
      "│  └ 10\n",
      "│  │  └ layer\n",
      "│  └ 11\n",
      "│  │  └ layer\n",
      "└ final_layer_norm\n",
      "└ dropout\n",
      "decoder\n",
      "└ embed_tokens\n",
      "└ block\n",
      "│  └ 0\n",
      "│  │  └ layer\n",
      "│  └ 1\n",
      "│  │  └ layer\n",
      "│  └ 2\n",
      "│  │  └ layer\n",
      "│  └ 3\n",
      "│  │  └ layer\n",
      "│  └ 4\n",
      "│  │  └ layer\n",
      "│  └ 5\n",
      "│  │  └ layer\n",
      "│  └ 6\n",
      "│  │  └ layer\n",
      "│  └ 7\n",
      "│  │  └ layer\n",
      "│  └ 8\n",
      "│  │  └ layer\n",
      "│  └ 9\n",
      "│  │  └ layer\n",
      "│  └ 10\n",
      "│  │  └ layer\n",
      "│  └ 11\n",
      "│  │  └ layer\n",
      "└ final_layer_norm\n",
      "└ dropout\n",
      "lm_head\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T00:08:58.084881Z",
     "start_time": "2025-05-11T00:04:21.565299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 모델 학습 및 평가\n",
    "\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "def calc_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "\n",
    "def train(model, optimizer, dataloader):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for source_ids, source_mask, target_ids, target_mask in dataloader:\n",
    "        decoder_input_ids = target_ids[:, :-1].contiguous()\n",
    "        labels = target_ids[:, 1:].clone().detach()\n",
    "        labels[target_ids[:, 1:] == tokenizer.pad_token_id] = -100\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=source_ids,\n",
    "            attention_mask=source_mask,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            labels=labels,\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "def evaluation(model, dataloader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "\n",
    "        for source_ids, source_mask, target_ids, target_mask in dataloader:\n",
    "            decoder_input_ids = target_ids[:, :-1].contiguous()\n",
    "            labels = target_ids[:, 1:].clone().detach()\n",
    "            labels[target_ids[:, 1:] == tokenizer.pad_token_id] = -100\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=source_ids,\n",
    "                attention_mask=source_mask,\n",
    "                decoder_input_ids=decoder_input_ids,\n",
    "                labels=labels,\n",
    "            )\n",
    "\n",
    "            loss = outputs.loss\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss = val_loss / len(dataloader)\n",
    "    return val_loss\n",
    "\n",
    "\n",
    "best_loss = 10000\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train(model, optimizer, train_dataloader)\n",
    "    val_loss = evaluation(model, valid_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}: Train Loss: {train_loss:.4f} Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"./models/T5ForConditionalGeneration.pt\")\n",
    "        print(\"Saved the model weights\")"
   ],
   "id": "8a176cfd49d92af8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 4.1245 Val Loss: 2.7325\n",
      "Saved the model weights\n",
      "Epoch 2: Train Loss: 2.8438 Val Loss: 2.4025\n",
      "Saved the model weights\n",
      "Epoch 3: Train Loss: 2.5413 Val Loss: 2.2528\n",
      "Saved the model weights\n",
      "Epoch 4: Train Loss: 2.3658 Val Loss: 2.1683\n",
      "Saved the model weights\n",
      "Epoch 5: Train Loss: 2.2361 Val Loss: 2.1131\n",
      "Saved the model weights\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T00:08:58.478592Z",
     "start_time": "2025-05-11T00:08:58.113169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 생성모델 테스트\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for source_ids, source_mask, target_ids, target_mask in test_dataloader:\n",
    "        generated_ids = model.generate(\n",
    "            input_ids=source_ids,\n",
    "            attention_mask=source_mask,\n",
    "            max_length=128,\n",
    "            num_beams=3,\n",
    "            repetition_penalty=2.5,\n",
    "            length_penalty=1.0,\n",
    "            early_stopping=True,\n",
    "        )\n",
    "\n",
    "        for generated, target in zip(generated_ids, target_ids):\n",
    "            pred = tokenizer.decode(\n",
    "                generated, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "            )\n",
    "            actual = tokenizer.decode(\n",
    "                target, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "            )\n",
    "            print(\"Generated Headline Text:\", pred)\n",
    "            print(\"Actual Headline Text   :\", actual)\n",
    "        break"
   ],
   "id": "dba40ceb01ab7c50",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Headline Text: Clinton leads Trump by 4 percentage points in a four-war race for Nov. 8 election\n",
      "Actual Headline Text   : Clinton leads Trump by 4 points in Washington Post: ABC News poll\n",
      "Generated Headline Text: senators question Gorsuch's independence in light of Trump travel ban\n",
      "Actual Headline Text   : Democrats question independence of Trump Supreme Court nominee\n",
      "Generated Headline Text: u.S. warns Saudi Arabia over Yemen humanitarian situation could constrain U.S. aid\n",
      "Actual Headline Text   : In push for Yemen aid, U.S. warned Saudis of threats in Congress\n",
      "Generated Headline Text: Romanian anti-corruption prosecutors open investigation into Social Democrat party leader Liviu Dragnea\n",
      "Actual Headline Text   : Romanian ruling party leader investigated over 'criminal group'\n",
      "Generated Headline Text: environmental activist endorses Hillary Clinton for U.S. president a day after she secured Democratic nomination\n",
      "Actual Headline Text   : Billionaire environmental activist Tom Steyer endorses Clinton\n",
      "Generated Headline Text: television presenter Ri Chun Hee delivers news of Pyongyang nuclear test with gusto\n",
      "Actual Headline Text   : Voice of triumph or doom: North Korean presenter back in limelight for nuclear test\n",
      "Generated Headline Text: two activists jailed for plotting against Maduro freed, opposition says\n",
      "Actual Headline Text   : Venezuela frees two anti-Maduro activists; scores still jailed\n",
      "Generated Headline Text: McCarthy still troubled by Clinton's use of personal email server\n",
      "Actual Headline Text   : House No. 2 Republican says still questions Clinton's judgment in email matter\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
