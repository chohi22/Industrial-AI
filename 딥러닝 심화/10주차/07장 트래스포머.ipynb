{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 트랜스포머",
   "id": "f2ba6cc87b86f3c7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 위치 인코딩",
   "id": "a38a351f48a848d8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T20:39:39.325044Z",
     "start_time": "2025-05-08T20:39:39.252363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from Transformer import SRC_LANGUAGE, TGT_LANGUAGE, UNK_IDX, special_symbols, criterion, text_transform, data_iter, \\\n",
    "    dataloader, source_tensor\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "encoding = PositionalEncoding(d_model=128, max_len=50)\n",
    "\n",
    "\n",
    "plt.pcolormesh(encoding.pe.numpy().squeeze(), cmap='RdBu')\n",
    "plt.xlabel(\"Enbedding Dimesion\")\n",
    "plt.xlim((0,128))\n",
    "plt.ylabel(\"Position\")\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ],
   "id": "8632e3f71d0dd973",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Transformer'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 6\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m nn\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m pyplot \u001B[38;5;28;01mas\u001B[39;00m plt\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mTransformer\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m SRC_LANGUAGE, TGT_LANGUAGE, UNK_IDX, special_symbols, criterion, text_transform, data_iter, \\\n\u001B[1;32m      7\u001B[0m     dataloader, source_tensor\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mPositionalEncoding\u001B[39;00m(nn\u001B[38;5;241m.\u001B[39mModule):\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, d_model, max_len, dropout\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.1\u001B[39m):\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'Transformer'"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 데이터세트 다운로드 및 전처리",
   "id": "7e9768e2db8726f1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T20:39:39.341172Z",
     "start_time": "2025-05-08T12:06:45.940214Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chohi/project/ai/DeepLearningDeepen/DeepLearningAdv/.venv/lib/python3.9/site-packages/torchtext/datasets/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/Users/chohi/project/ai/DeepLearningDeepen/DeepLearningAdv/.venv/lib/python3.9/site-packages/torchtext/data/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/Users/chohi/project/ai/DeepLearningDeepen/DeepLearningAdv/.venv/lib/python3.9/site-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/Users/chohi/project/ai/DeepLearningDeepen/DeepLearningAdv/.venv/lib/python3.9/site-packages/torchtext/utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/Users/chohi/project/ai/DeepLearningDeepen/DeepLearningAdv/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Transform:\n",
      "{'de': functools.partial(<function _spacy_tokenize at 0x136a55dc0>, spacy=<spacy.lang.de.German object at 0x136a047c0>), 'en': functools.partial(<function _spacy_tokenize at 0x136a55dc0>, spacy=<spacy.lang.en.English object at 0x157555e80>)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chohi/project/ai/DeepLearningDeepen/DeepLearningAdv/.venv/lib/python3.9/site-packages/torchdata/datapipes/__init__.py:18: UserWarning: \n",
      "################################################################################\n",
      "WARNING!\n",
      "The 'datapipes', 'dataloader2' modules are deprecated and will be removed in a\n",
      "future torchdata release! Please see https://github.com/pytorch/data/issues/1196\n",
      "to learn more and leave feedback.\n",
      "################################################################################\n",
      "\n",
      "  deprecation_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Transform:\n",
      "{'de': Vocab(), 'en': Vocab()}\n"
     ]
    }
   ],
   "execution_count": 2,
   "source": [
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "\n",
    "def generate_token(text_iter, language):\n",
    "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
    "\n",
    "    for text in text_iter:\n",
    "        yield token_transform[language](text[language_index[language]])\n",
    "\n",
    "\n",
    "SRC_LANGUAGE = \"de\"\n",
    "TGT_LANGUAGE = \"en\"\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "special_symbols = [\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\", \"<special>\"]\n",
    "\n",
    "token_transform = {\n",
    "    SRC_LANGUAGE: get_tokenizer(\"spacy\", language=\"de_core_news_sm\"),\n",
    "    TGT_LANGUAGE: get_tokenizer(\"spacy\", language=\"en_core_web_sm\"),\n",
    "}\n",
    "\n",
    "print(\"Token Transform:\")\n",
    "print(token_transform)\n",
    "\n",
    "vocab_transform = {}\n",
    "for language in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    train_iter = Multi30k(split=\"train\", language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    vocab_transform[language] = build_vocab_from_iterator(\n",
    "        generate_token(train_iter, language),\n",
    "        min_freq=1,\n",
    "        specials=special_symbols,\n",
    "        special_first=True,\n",
    "    )\n",
    "\n",
    "for language in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    vocab_transform[language].set_default_index(UNK_IDX)\n",
    "\n",
    "print(\"Vocab Transform:\")\n",
    "print(vocab_transform)"
   ],
   "id": "3826b2bd589337a6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 트랜스포터 모델 구성",
   "id": "5be09b60864cd058"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T20:39:39.359620Z",
     "start_time": "2025-05-08T14:00:43.015594Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 3,
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[: x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "\n",
    "\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_encoder_layers,\n",
    "                 num_decoder_layers,\n",
    "                 emb_size,\n",
    "                 max_len,\n",
    "                 nhead,\n",
    "                 src_vocab_size,\n",
    "                 tgt_vocab_size,\n",
    "                 dim_feedforward,\n",
    "                 dropout=0.1,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(emb_size, max_len, dropout=dropout)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=emb_size,\n",
    "            nhead=nhead,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "\n",
    "    def forward(self, src, tgt, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, memory_key_padding_mask,):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(tgt))\n",
    "        outs = self.transformer(\n",
    "            src = src_emb,\n",
    "            tgt = tgt_emb,\n",
    "            src_mask = src_mask,\n",
    "            tgt_mask = tgt_mask,\n",
    "            memory_mask = None,\n",
    "            src_key_padding_mask = src_padding_mask,\n",
    "            tgt_key_padding_mask = tgt_padding_mask,\n",
    "            memory_key_padding_mask = memory_key_padding_mask\n",
    "        )\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        return self.transformer.encoder(\n",
    "            self.positional_encoding(self.src_tok_emb(src)), src_mask\n",
    "        )\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask):\n",
    "        return self.transformer.decoder(\n",
    "            self.positional_encoding(self.tgt_tok_emb(tgt)), memory, tgt_mask\n",
    "        )\n"
   ],
   "id": "dc2d24f84ab50cf0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 트랜스포머 모델 구조",
   "id": "973bd150033e7419"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T20:39:39.366381Z",
     "start_time": "2025-05-08T14:05:05.009140Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chohi/project/ai/DeepLearningDeepen/DeepLearningAdv/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "/Users/chohi/project/ai/DeepLearningDeepen/DeepLearningAdv/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src_tok_emb\n",
      "└ embedding\n",
      "tgt_tok_emb\n",
      "└ embedding\n",
      "positional_encoding\n",
      "└ dropout\n",
      "transformer\n",
      "└ encoder\n",
      "│  └ layers\n",
      "│  │  └ 0\n",
      "│  │  └ 1\n",
      "│  │  └ 2\n",
      "│  └ norm\n",
      "└ decoder\n",
      "│  └ layers\n",
      "│  │  └ 0\n",
      "│  │  └ 1\n",
      "│  │  └ 2\n",
      "│  └ norm\n",
      "generator\n"
     ]
    }
   ],
   "execution_count": 4,
   "source": [
    "\n",
    "from torch import optim\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = Seq2SeqTransformer(\n",
    "    num_encoder_layers=3,\n",
    "    num_decoder_layers=3,\n",
    "    emb_size=512,\n",
    "    max_len=512,\n",
    "    nhead=8,\n",
    "    src_vocab_size=len(vocab_transform[SRC_LANGUAGE]),\n",
    "    tgt_vocab_size=len(vocab_transform[TGT_LANGUAGE]),\n",
    "    dim_feedforward=512,\n",
    ").to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "for main_name, main_module in model.named_children():\n",
    "    print(main_name)\n",
    "    for sub_name, sub_module in main_module.named_children():\n",
    "        print(\"└\", sub_name)\n",
    "        for ssub_name, ssub_module in sub_module.named_children():\n",
    "            print(\"│  └\", ssub_name)\n",
    "            for sssub_name, sssub_module in ssub_module.named_children():\n",
    "                print(\"│  │  └\", sssub_name)"
   ],
   "id": "1ab8196d92763a31"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 배치 데이터 생성",
   "id": "c3b13dbfb6e3d783"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T20:39:39.389399Z",
     "start_time": "2025-05-08T14:17:58.125605Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(source, target):\n",
      "('Eine Gruppe von Männern lädt Baumwolle auf einen Lastwagen', 'A group of men are loading cotton onto a truck')\n",
      "source_batch: torch.Size([35, 128])\n",
      "tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
      "        [  15,    6,    6,  ...,    6,   22,    6],\n",
      "        [  39,   13,   36,  ...,   13, 1751,   70],\n",
      "        ...,\n",
      "        [   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [   1,    1,    1,  ...,    1,    1,    1]])\n",
      "target_batch: torch.Size([30, 128])\n",
      "tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
      "        [   7,    7,    7,  ...,  251,   20,    7],\n",
      "        [  40,   13,   36,  ...,   13, 3255,   62],\n",
      "        ...,\n",
      "        [   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [   1,    1,    1,  ...,    1,    1,    1]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chohi/project/ai/DeepLearningDeepen/DeepLearningAdv/.venv/lib/python3.9/site-packages/torch/utils/data/datapipes/iter/combining.py:337: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
      "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
     ]
    }
   ],
   "execution_count": 6,
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func\n",
    "\n",
    "def input_transform(token_ids):\n",
    "    return torch.cat(\n",
    "        (torch.tensor([BOS_IDX]),torch.tensor(token_ids),torch.tensor([EOS_IDX]))\n",
    "    )\n",
    "\n",
    "def collator(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
    "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "    return src_batch, tgt_batch\n",
    "\n",
    "\n",
    "text_transform = {}\n",
    "for language in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    text_transform[language] = sequential_transforms(\n",
    "        token_transform[language],vocab_transform[language],input_transform\n",
    "    )\n",
    "\n",
    "data_iter = Multi30k(split=\"valid\", language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "dataloader = DataLoader(data_iter, batch_size=BATCH_SIZE, collate_fn=collator)\n",
    "source_tensor, target_tensor = next(iter(dataloader))\n",
    "\n",
    "print(\"(source, target):\")\n",
    "print(next(iter(data_iter)))\n",
    "\n",
    "print(\"source_batch:\", source_tensor.shape)\n",
    "print(source_tensor)\n",
    "\n",
    "print(\"target_batch:\", target_tensor.shape)\n",
    "print(target_tensor)"
   ],
   "id": "9f3ffc38a943025f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 어텐션 마스크 생성",
   "id": "fa94ea92b202c8d5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T20:39:39.397978Z",
     "start_time": "2025-05-08T14:23:52.764912Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_mask: torch.Size([35, 35])\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "target_mask: torch.Size([29, 29])\n",
      "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf,\n",
      "         -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0.]])\n",
      "source_padding_mask: torch.Size([128, 35])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        ...,\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True]])\n",
      "target_padding_mask: torch.Size([128, 29])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        ...,\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True]])\n"
     ]
    }
   ],
   "execution_count": 7,
   "source": [
    "\n",
    "def generate_square_subsequent_mask(s):\n",
    "    mask = (torch.triu(torch.ones((s, s), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = (\n",
    "        mask.float().masked_fill(mask == 0, float(\"-inf\")).masked_fill(mask == 1, float(0.0))\n",
    "    )\n",
    "    return mask\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len), device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0,1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0,1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n",
    "\n",
    "\n",
    "target_input = target_tensor[:-1, :]\n",
    "target_out = target_tensor[1:, :]\n",
    "\n",
    "source_mask, target_mask, source_padding_mask, target_padding_mask = create_mask(\n",
    "    source_tensor, target_input\n",
    ")\n",
    "\n",
    "print(\"source_mask:\", source_mask.shape)\n",
    "print(source_mask)\n",
    "print(\"target_mask:\", target_mask.shape)\n",
    "print(target_mask)\n",
    "print(\"source_padding_mask:\", source_padding_mask.shape)\n",
    "print(source_padding_mask)\n",
    "print(\"target_padding_mask:\", target_padding_mask.shape)\n",
    "print(target_padding_mask)\n"
   ],
   "id": "308040d4dd929b9a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 모델 학습 및 평가",
   "id": "745f9c3a89b0993a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T20:39:39.399195Z",
     "start_time": "2025-05-08T14:31:03.860551Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chohi/project/ai/DeepLearningDeepen/DeepLearningAdv/.venv/lib/python3.9/site-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, train loss: 4.630, val loss: 3.903\n",
      "Epoch: 2, train loss: 3.696, val loss: 3.644\n",
      "Epoch: 3, train loss: 3.438, val loss: 3.541\n",
      "Epoch: 4, train loss: 3.287, val loss: 3.506\n",
      "Epoch: 5, train loss: 3.173, val loss: 3.499\n"
     ]
    }
   ],
   "execution_count": 8,
   "source": [
    "def run(model, optimizer, criterion, split):\n",
    "    model.train() if split == \"train\" else model.eval()\n",
    "    data_iter = Multi30k(split=split, language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    dataloader = DataLoader(data_iter, batch_size=BATCH_SIZE, collate_fn=collator)\n",
    "\n",
    "    losses = 0\n",
    "    for source_batch, target_batch in dataloader:\n",
    "        source_batch = source_batch.to(DEVICE)\n",
    "        target_batch = target_batch.to(DEVICE)\n",
    "\n",
    "        target_input = target_batch[:-1, :]\n",
    "        target_output = target_batch[1:, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(\n",
    "            source_batch, target_input\n",
    "        )\n",
    "\n",
    "        logits = model(\n",
    "            src=source_batch,\n",
    "            tgt=target_input,\n",
    "            src_mask=src_mask,\n",
    "            tgt_mask=tgt_mask,\n",
    "            src_padding_mask=src_padding_mask,\n",
    "            tgt_padding_mask=tgt_padding_mask,\n",
    "            memory_key_padding_mask=src_padding_mask,\n",
    "        )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(logits.view(-1, logits.shape[-1]), target_output.reshape(-1))\n",
    "        if split == \"train\":\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses/len(list(dataloader))\n",
    "\n",
    "for epoch in range(5):\n",
    "    train_loss = run(model, optimizer, criterion, \"train\")\n",
    "    val_loss = run(model, optimizer, criterion, \"valid\")\n",
    "    print(f\"Epoch: {epoch+1}, train loss: {train_loss:.3f}, val loss: {val_loss:.3f}\")"
   ],
   "id": "d500bbb40a5ed0c1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 트랜스포머 모델 번역 결과",
   "id": "8103e22663ca23d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T20:39:50.050021Z",
     "start_time": "2025-05-08T20:39:49.518635Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def greedy_decode(model, source_tensor, source_mask, max_len, start_symbol):\n",
    "    source_tensor = source_tensor.to(DEVICE)\n",
    "    source_mask = source_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(source_tensor, source_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len - 1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        target_mask = generate_square_subsequent_mask(ys.size(0))\n",
    "        target_mask = target_mask.type(torch.bool).to(DEVICE)\n",
    "\n",
    "        out = model.decode(ys, memory, target_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat(\n",
    "            [ys, torch.ones(1, 1).type_as(source_tensor.data).fill_(next_word)], dim=0\n",
    "        )\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "\n",
    "def translate(model, source_sentence):\n",
    "    model.eval()\n",
    "    source_tensor = text_transform[SRC_LANGUAGE](source_sentence).view(-1, 1)\n",
    "    num_tokens = source_tensor.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(\n",
    "        model, source_tensor, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX\n",
    "    ).flatten()\n",
    "    output = vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))[1:-1]\n",
    "    return \" \".join(output)\n",
    "\n",
    "\n",
    "output_oov = translate(model, \"Eine Gruppe von Menschen steht vor einem Iglu .\")\n",
    "output = translate(model, \"Eine Gruppe von Menschen steht vor einem Gebäude .\")\n",
    "print(output_oov)\n",
    "print(output)\n"
   ],
   "id": "2a02392554192515",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two men are playing basketball on a field .\n",
      "Two men are playing soccer on a beach .\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ca5eb26536f29208"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
