{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-29T06:23:51.519683Z",
     "start_time": "2025-03-29T06:23:49.717891Z"
    }
   },
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.48235, 0.45882, 0.40784],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "image = Image.open(\"../datasets/images/cat.jpg\")\n",
    "inputs = transform(image).unsqueeze(0)\n",
    "\n",
    "model = models.vgg16(num_classes=2, pretrained=False)\n",
    "model.load_state_dict(torch.load(\"../models/VGG16.pt\"))\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "model_static_quantized = torch.jit.load(\"../models/PTSQ_VGG16.pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    start_time = time.time()\n",
    "    outputs = model(inputs.to(device))\n",
    "    file_size = os.path.getsize(\"../models/VGG16.pt\") / 1e6\n",
    "    print(\"양자화 적용 전:\")\n",
    "    print(f\"출력 결과: {outputs}\")\n",
    "    print(f\"추론 시간: {time.time() - start_time:.4f}s\")\n",
    "    print(f\"파일 크기: {file_size:.2f} MB\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "outputs = model_static_quantized(inputs)\n",
    "file_size = os.path.getsize(\"../models/PTSQ_VGG16.pt\") / 1e6\n",
    "end_time = time.time() - start_time\n",
    "print(\"양자화 적용 후:\")\n",
    "print(f\"출력 결과: {outputs}\")\n",
    "print(f\"추론 시간: {end_time:.4f}s\")\n",
    "print(f\"파일 크기: {file_size:.2f} MB\")"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../models/VGG16.pt'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 25\u001B[0m\n\u001B[1;32m     22\u001B[0m inputs \u001B[38;5;241m=\u001B[39m transform(image)\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     24\u001B[0m model \u001B[38;5;241m=\u001B[39m models\u001B[38;5;241m.\u001B[39mvgg16(num_classes\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, pretrained\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m---> 25\u001B[0m model\u001B[38;5;241m.\u001B[39mload_state_dict(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m../models/VGG16.pt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     27\u001B[0m device \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     28\u001B[0m model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[0;32m~/project/ai/DeepLearningDeepen/DeepLearningAdv/.venv/lib/python3.9/site-packages/torch/serialization.py:1425\u001B[0m, in \u001B[0;36mload\u001B[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[0m\n\u001B[1;32m   1422\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m pickle_load_args\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[1;32m   1423\u001B[0m     pickle_load_args[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1425\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43m_open_file_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m opened_file:\n\u001B[1;32m   1426\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_zipfile(opened_file):\n\u001B[1;32m   1427\u001B[0m         \u001B[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001B[39;00m\n\u001B[1;32m   1428\u001B[0m         \u001B[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001B[39;00m\n\u001B[1;32m   1429\u001B[0m         \u001B[38;5;66;03m# reset back to the original position.\u001B[39;00m\n\u001B[1;32m   1430\u001B[0m         orig_position \u001B[38;5;241m=\u001B[39m opened_file\u001B[38;5;241m.\u001B[39mtell()\n",
      "File \u001B[0;32m~/project/ai/DeepLearningDeepen/DeepLearningAdv/.venv/lib/python3.9/site-packages/torch/serialization.py:751\u001B[0m, in \u001B[0;36m_open_file_like\u001B[0;34m(name_or_buffer, mode)\u001B[0m\n\u001B[1;32m    749\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_open_file_like\u001B[39m(name_or_buffer, mode):\n\u001B[1;32m    750\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_path(name_or_buffer):\n\u001B[0;32m--> 751\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_open_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    752\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    753\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m mode:\n",
      "File \u001B[0;32m~/project/ai/DeepLearningDeepen/DeepLearningAdv/.venv/lib/python3.9/site-packages/torch/serialization.py:732\u001B[0m, in \u001B[0;36m_open_file.__init__\u001B[0;34m(self, name, mode)\u001B[0m\n\u001B[1;32m    731\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, mode):\n\u001B[0;32m--> 732\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../models/VGG16.pt'"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T06:23:58.689792Z",
     "start_time": "2025-03-29T06:23:58.686927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "# 양자화 백엔드 설정\n",
    "torch.backends.quantized.engine = 'qnnpack'  # 또는 'fbgemm'\n",
    "\n",
    "print(\"Current quantized engine:\", torch.backends.quantized.engine)\n"
   ],
   "id": "b2c85a5c36b4475c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current quantized engine: qnnpack\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T06:24:03.517154Z",
     "start_time": "2025-03-29T06:24:01.340429Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "\n",
    "# 백엔드 활성화\n",
    "torch.backends.quantized.engine = 'qnnpack'\n",
    "\n",
    "# 기본 VGG16 모델 (pretrained=False 또는 pretrained=True)\n",
    "device = torch.device('cpu')  # 양자화 모델은 CPU에서 실행됨\n",
    "original_model = models.vgg16(pretrained=False)\n",
    "original_model.to(device)\n",
    "\n",
    "# 동적 양자화 적용\n",
    "quantized_vgg16 = torch.quantization.quantize_dynamic(\n",
    "    original_model,  # 원본 모델\n",
    "    {torch.nn.Linear},  # 양자화할 레이어 종류\n",
    "    dtype=torch.qint8  # 양자화 데이터 타입\n",
    ")\n",
    "\n",
    "# 예제 입력\n",
    "dummy_input = torch.rand(1, 3, 224, 224).to(device)\n",
    "\n",
    "# 테스트 실행\n",
    "output = quantized_vgg16(dummy_input)\n",
    "print(output)\n"
   ],
   "id": "165857e2f3e996e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.0256e-02,  2.8610e-02,  1.5141e-02, -1.1033e-02,  3.6020e-02,\n",
      "         -4.4120e-03, -1.8670e-02,  9.5491e-03,  1.3924e-02,  4.2411e-03,\n",
      "         -1.2143e-02,  4.3209e-02,  2.7170e-02,  3.7288e-02, -3.2777e-02,\n",
      "          3.5690e-03, -4.2151e-02, -3.7039e-03, -1.7512e-02, -1.3442e-03,\n",
      "         -3.6341e-02, -4.4383e-02, -1.4925e-02, -3.0506e-03,  2.1187e-02,\n",
      "          1.9326e-02,  4.0454e-02, -2.9515e-02, -5.6498e-03,  8.1603e-03,\n",
      "          1.8804e-02, -3.9759e-04,  2.7200e-02, -1.5769e-02,  2.6792e-02,\n",
      "          3.6987e-02,  2.0566e-02,  1.0887e-02,  2.6035e-02,  1.0880e-02,\n",
      "         -5.1104e-02,  3.8977e-02,  8.2212e-03, -1.3021e-03,  2.0488e-03,\n",
      "          3.8707e-02, -1.7959e-02, -5.5744e-02, -4.0680e-03,  2.4547e-02,\n",
      "          2.1758e-02,  1.1656e-02,  1.8289e-02,  2.9709e-03,  3.9912e-03,\n",
      "          5.1492e-02, -3.6092e-04,  1.0764e-03,  1.6449e-02,  3.0676e-02,\n",
      "         -2.9121e-02, -5.9305e-02,  6.8805e-03, -2.3615e-02, -4.8412e-02,\n",
      "         -3.2174e-03,  1.7636e-02,  1.8987e-02,  2.6068e-02,  5.5537e-02,\n",
      "         -1.2228e-02,  5.6848e-02,  1.5229e-02, -5.9414e-02, -3.0768e-02,\n",
      "          3.3376e-02,  4.6210e-02,  2.8444e-02,  2.0831e-02,  2.6720e-02,\n",
      "          5.0633e-02, -6.3155e-03, -3.4237e-02, -6.0721e-02, -1.1158e-02,\n",
      "         -6.2874e-03,  3.2954e-02,  6.4416e-02,  6.4931e-02,  2.0650e-02,\n",
      "          9.1882e-03,  1.3286e-02, -2.1130e-02,  7.3093e-03,  3.2549e-02,\n",
      "         -1.3362e-03,  4.5784e-02, -1.1083e-03, -8.9596e-03,  4.7417e-03,\n",
      "          8.2116e-03, -3.2686e-02,  2.2067e-02,  8.2894e-03, -4.5324e-02,\n",
      "          3.1924e-02,  3.7556e-02,  1.2619e-02,  3.9826e-02, -4.9865e-02,\n",
      "          2.5439e-02,  3.6621e-02,  5.4782e-03, -1.0112e-02, -1.4706e-02,\n",
      "          6.7574e-03, -3.9329e-02,  3.4090e-03,  2.3329e-02,  1.8767e-02,\n",
      "         -4.3103e-02, -1.9189e-02, -1.4502e-02, -7.3166e-03,  4.1994e-02,\n",
      "         -6.7967e-02,  2.0778e-02, -1.5100e-03,  2.3045e-02,  2.7396e-02,\n",
      "         -7.9406e-03,  3.5027e-02, -3.5430e-02,  2.2015e-02, -2.7441e-02,\n",
      "          5.2970e-02,  1.4203e-02, -1.3949e-03,  1.0780e-02,  2.3980e-03,\n",
      "         -5.8947e-02, -2.2786e-02,  6.7596e-03,  5.4384e-03, -1.0390e-02,\n",
      "         -8.6085e-05,  9.3989e-03,  6.5686e-03,  6.7261e-03, -3.3303e-02,\n",
      "          2.3763e-02,  7.2037e-02,  5.7613e-04,  2.4171e-02,  4.2269e-02,\n",
      "         -2.9072e-02, -1.1481e-03, -4.3760e-03,  2.2613e-02, -2.7316e-02,\n",
      "         -7.0093e-03,  1.7218e-02,  2.4467e-03, -4.8125e-03, -1.1461e-02,\n",
      "         -6.7736e-03,  1.0649e-02,  7.7203e-03, -1.3687e-02,  1.8298e-02,\n",
      "          9.6518e-03, -2.8105e-02,  3.5388e-02, -2.8075e-02, -5.7502e-03,\n",
      "          2.1721e-02, -3.3063e-02, -2.6137e-02, -2.9189e-02,  1.9315e-03,\n",
      "         -1.4528e-02,  2.5953e-04,  2.7148e-02,  9.4193e-03,  2.9329e-02,\n",
      "          2.0227e-02,  1.2527e-02, -3.0253e-02,  2.3779e-02,  4.5090e-03,\n",
      "          9.2692e-03, -3.8745e-03,  5.1463e-02, -4.0071e-02, -2.3725e-03,\n",
      "         -3.2184e-02,  2.1120e-02, -9.8816e-03, -3.9269e-02, -9.7583e-03,\n",
      "          9.8007e-03,  1.9149e-03, -1.4926e-02,  1.3069e-02,  3.8464e-03,\n",
      "          7.8191e-03,  2.0722e-02,  3.9127e-03, -2.4062e-02,  9.0833e-03,\n",
      "         -5.5158e-04, -1.4183e-02, -1.6452e-04, -9.2622e-03,  3.5841e-02,\n",
      "         -1.3307e-02, -5.7566e-03,  4.9244e-02, -8.7747e-03,  2.2936e-02,\n",
      "          1.5082e-02, -4.7616e-02, -1.2970e-02,  1.3367e-02,  2.6287e-02,\n",
      "         -2.3689e-03, -1.4437e-02,  1.9594e-02,  8.2425e-03,  2.6217e-02,\n",
      "          2.5975e-03,  1.7135e-02,  1.4559e-02,  4.2890e-02,  1.0972e-02,\n",
      "          2.5857e-02,  4.7137e-03, -1.4284e-03,  4.0877e-02,  4.3100e-02,\n",
      "         -1.9628e-02,  2.4632e-02,  1.3469e-02, -1.2582e-02, -1.4640e-02,\n",
      "         -9.3782e-03, -1.1128e-02,  1.7978e-02, -2.1489e-04,  1.6424e-02,\n",
      "          1.9469e-02, -5.6800e-02,  9.1665e-03,  3.5000e-02, -5.0372e-02,\n",
      "         -2.1310e-02,  1.3807e-02, -5.1881e-03, -4.8567e-02, -8.7584e-03,\n",
      "         -6.5992e-02, -4.9432e-02,  1.7137e-02, -8.8126e-03,  4.4873e-03,\n",
      "          1.2606e-02,  1.1426e-02, -6.0174e-02,  9.0970e-03,  2.3191e-02,\n",
      "          1.1450e-02,  6.0575e-03, -3.8470e-02,  2.2004e-02, -3.7027e-02,\n",
      "         -1.7526e-02, -3.2320e-02,  3.1076e-02,  1.7383e-03, -5.4607e-03,\n",
      "         -1.0068e-02, -2.9253e-02,  3.6968e-02,  1.0028e-02,  2.0044e-02,\n",
      "          6.2154e-03,  1.3855e-02,  2.8665e-02,  1.7823e-04, -4.4932e-02,\n",
      "         -2.2238e-02, -1.1086e-02,  2.0301e-02,  8.1270e-02,  1.1420e-02,\n",
      "          1.2262e-02, -1.9680e-02,  9.2781e-03,  6.9229e-03,  3.3734e-02,\n",
      "         -1.5828e-02,  1.1574e-02,  2.6932e-02, -2.4133e-02, -2.4938e-02,\n",
      "         -8.3318e-03,  8.7377e-03, -4.7162e-03,  1.4527e-02, -1.6155e-02,\n",
      "         -1.6644e-02,  5.4351e-02,  3.4785e-04, -2.5259e-02, -8.8534e-03,\n",
      "          1.3194e-02,  2.9340e-02, -3.0312e-03,  2.7428e-02, -2.6176e-03,\n",
      "         -3.5308e-03, -1.2886e-02,  5.5920e-03, -1.6903e-02, -4.4423e-02,\n",
      "          3.4865e-02, -2.2704e-02,  1.2785e-04, -3.3278e-02,  1.5152e-02,\n",
      "         -1.6331e-02, -8.6736e-03, -1.4810e-02,  3.0625e-02,  3.6267e-02,\n",
      "          7.3409e-03,  5.4269e-02, -9.1276e-03,  7.0329e-03,  3.6784e-02,\n",
      "         -2.0897e-02, -2.1874e-02, -1.2963e-02, -2.0730e-02, -1.4876e-02,\n",
      "         -2.0532e-02, -7.7816e-02, -1.9686e-02,  1.3109e-02,  1.2858e-02,\n",
      "          1.2258e-02,  1.7823e-02,  4.0003e-02,  2.5858e-04, -7.7442e-03,\n",
      "          5.9813e-03,  4.0803e-02, -1.0384e-02, -3.0154e-02,  4.5860e-02,\n",
      "          1.4890e-04,  1.3945e-02, -1.7776e-02,  3.2980e-02,  5.4403e-03,\n",
      "         -1.2217e-02, -2.6983e-03, -1.9251e-02,  5.0063e-03,  2.4031e-02,\n",
      "         -2.2508e-02,  5.6916e-02,  2.6048e-02, -6.0897e-05, -2.0078e-02,\n",
      "         -4.7507e-02,  3.9462e-02,  2.3304e-02,  2.5587e-02,  4.4558e-02,\n",
      "         -7.7477e-03,  9.7646e-03, -6.1918e-04,  1.9439e-03,  2.2870e-02,\n",
      "          2.3003e-02,  2.8842e-03, -2.3272e-03, -1.7050e-02,  2.5589e-02,\n",
      "         -7.0663e-03, -5.1865e-02, -1.0271e-02,  4.0640e-02, -7.8121e-03,\n",
      "          8.1654e-03,  2.9016e-02, -2.5213e-02, -5.3551e-02,  1.6005e-02,\n",
      "          3.1129e-02,  2.9574e-02,  3.7134e-02, -8.7791e-03, -3.9509e-02,\n",
      "         -4.6974e-03,  3.3869e-02, -1.5693e-03, -1.3101e-02, -5.2041e-02,\n",
      "          5.6392e-03, -8.9679e-03, -1.5775e-02,  4.7013e-02,  2.7294e-02,\n",
      "          1.9286e-03, -4.3020e-03,  1.3608e-02,  1.2696e-03, -4.7856e-02,\n",
      "          1.8706e-03, -3.2564e-02,  1.3987e-03,  1.1516e-02, -2.8142e-02,\n",
      "          1.4626e-02,  1.7644e-02,  3.3660e-02,  1.7193e-02,  2.1030e-02,\n",
      "          1.2286e-02, -3.9507e-03, -1.2951e-02,  1.6520e-02, -3.1263e-02,\n",
      "          2.8054e-02,  1.6506e-02, -5.2098e-04, -8.3509e-03, -1.8583e-02,\n",
      "         -6.2881e-03,  2.3950e-02,  1.6518e-02,  2.4498e-02,  7.3026e-02,\n",
      "          4.2373e-04,  2.2570e-02, -2.0243e-02, -2.7030e-02, -2.5337e-02,\n",
      "          2.6047e-02,  2.3285e-02, -8.0649e-03,  3.2413e-02,  2.4662e-02,\n",
      "         -7.7333e-03,  8.8783e-03,  3.5834e-02,  3.6543e-02,  1.1468e-02,\n",
      "         -1.4883e-02, -3.5997e-02,  1.3515e-03,  1.9738e-02,  1.5039e-02,\n",
      "         -1.8586e-02,  2.7052e-02,  1.0480e-03, -2.0335e-02,  3.4893e-02,\n",
      "         -1.2885e-02,  6.0429e-03, -3.2706e-02,  3.5383e-02,  3.6985e-04,\n",
      "          6.0757e-03,  1.2121e-02,  3.2617e-03,  2.8216e-02,  2.1892e-02,\n",
      "         -5.9539e-03, -5.5581e-02, -3.2145e-03, -2.3415e-02, -1.0388e-02,\n",
      "         -1.6182e-02, -4.5456e-03,  1.8146e-02,  4.1678e-03, -2.1751e-02,\n",
      "          6.1197e-03,  2.6060e-02,  1.7617e-02,  2.3362e-02,  3.5821e-03,\n",
      "          1.0111e-02, -4.2840e-02, -2.7231e-02, -2.5309e-02,  2.9384e-03,\n",
      "          1.3306e-02,  4.1994e-02,  1.9688e-02,  1.7388e-02, -4.5190e-02,\n",
      "         -1.8234e-02,  1.8378e-02,  4.0129e-03, -7.6428e-03,  3.3248e-03,\n",
      "          4.8689e-03,  1.1829e-02, -1.8692e-02, -8.2301e-03, -3.6118e-02,\n",
      "          1.0973e-02, -9.3428e-03,  8.1676e-03,  3.1393e-02, -1.0094e-03,\n",
      "          4.2717e-02,  1.4712e-02, -2.2376e-03,  2.3858e-02,  1.8811e-04,\n",
      "         -1.3012e-03,  1.3040e-02, -3.7670e-02,  1.1044e-02,  4.6021e-03,\n",
      "          4.9671e-02, -1.3492e-02,  1.5310e-03,  1.0372e-03,  8.4280e-02,\n",
      "          3.1585e-02, -5.9090e-03, -2.6615e-02, -3.8816e-02, -4.9697e-02,\n",
      "          3.7909e-02,  3.5893e-02,  2.2564e-03, -3.0639e-02,  3.4189e-02,\n",
      "          4.3696e-03,  1.5722e-02, -1.8304e-03,  3.5819e-02,  5.7744e-02,\n",
      "          5.0135e-02,  6.7536e-03,  4.9256e-02, -3.0057e-02,  1.6076e-02,\n",
      "         -1.4203e-02,  5.1211e-03,  1.4138e-02,  1.3345e-02,  3.8292e-04,\n",
      "         -6.3793e-02, -1.6962e-02, -2.2424e-02, -1.6225e-02,  2.8617e-02,\n",
      "         -2.3839e-03,  2.0092e-02, -3.3060e-02, -3.9194e-03,  2.2690e-02,\n",
      "          2.2669e-03,  5.8085e-03, -1.8032e-02,  6.7179e-03, -3.6483e-02,\n",
      "          5.1103e-02,  1.2126e-02, -9.7717e-03, -4.2463e-02,  3.0927e-04,\n",
      "         -2.5465e-03,  4.2000e-02, -5.2235e-03,  3.3934e-02,  2.4073e-02,\n",
      "         -5.0535e-03,  2.9585e-02,  1.0012e-02, -2.3590e-02,  1.2322e-02,\n",
      "          4.0873e-02, -1.1610e-02,  2.0236e-02,  1.6981e-03, -2.1711e-02,\n",
      "          1.5140e-02,  6.7668e-02, -5.9275e-03, -1.6187e-03, -9.8195e-03,\n",
      "         -2.0968e-02,  1.0389e-02, -6.1516e-03,  1.0238e-02, -2.1527e-02,\n",
      "         -3.5308e-02,  4.0483e-02, -3.1064e-02, -7.2312e-03, -9.2226e-03,\n",
      "         -1.9304e-02, -1.0844e-03,  9.2867e-03, -1.2008e-02,  5.2282e-02,\n",
      "         -1.6503e-02,  2.0550e-02,  1.6688e-02, -1.3770e-02, -3.6346e-02,\n",
      "         -3.9303e-03,  3.5027e-03, -7.3364e-04, -3.4096e-02,  4.2392e-03,\n",
      "         -4.4271e-02,  1.1376e-03, -2.3797e-02,  7.8261e-03, -7.5255e-03,\n",
      "          8.0939e-03,  3.6833e-02,  3.2923e-02, -3.9338e-03, -2.6463e-03,\n",
      "          3.6787e-02, -6.6907e-02,  1.3373e-02, -3.2684e-02,  2.1740e-02,\n",
      "         -3.1278e-02, -4.4694e-03,  1.5563e-02,  9.9323e-03,  1.2663e-02,\n",
      "          3.3838e-03,  8.7810e-03,  2.9329e-02,  6.8881e-03, -3.4524e-02,\n",
      "         -2.2446e-02, -1.7149e-02,  2.8541e-02, -5.7840e-03,  1.7444e-02,\n",
      "          4.7857e-04,  5.9558e-04, -2.3809e-02, -1.1083e-02, -3.8930e-02,\n",
      "          1.6101e-02, -1.9957e-02, -7.8609e-03, -2.5219e-02,  1.7116e-02,\n",
      "         -6.2731e-03, -1.2215e-03, -2.2010e-02,  1.6440e-02,  4.8198e-02,\n",
      "          9.0042e-03,  3.0051e-02, -1.4719e-02,  2.5213e-02, -2.4726e-03,\n",
      "         -2.6536e-02,  3.1574e-02, -6.7574e-03, -5.8494e-02, -7.6520e-04,\n",
      "          1.0708e-02, -9.3297e-03, -2.6747e-02, -1.5975e-02,  1.3200e-04,\n",
      "          2.3966e-02,  1.0151e-02, -2.9668e-02,  7.2522e-03,  3.4229e-02,\n",
      "         -3.0767e-02,  2.2324e-02, -4.4141e-02, -3.9662e-02,  1.1255e-04,\n",
      "          5.7247e-03, -1.9380e-02,  2.8844e-02, -3.4530e-04,  2.3034e-02,\n",
      "         -1.8212e-02, -4.1835e-02, -2.8415e-03,  1.2605e-02,  4.0173e-05,\n",
      "         -1.0521e-02,  1.2524e-02,  2.6664e-02,  1.2627e-02, -7.0877e-04,\n",
      "          9.3799e-02, -2.1228e-03,  9.5153e-03,  1.8320e-02,  1.2569e-02,\n",
      "         -2.2445e-02, -2.2267e-02,  7.9081e-03, -4.1279e-02,  2.0103e-02,\n",
      "          1.1908e-03, -1.4837e-02,  2.7082e-02, -6.8409e-03, -3.1512e-02,\n",
      "         -4.5638e-03,  4.2626e-02, -2.3763e-03, -5.7164e-02, -8.9624e-04,\n",
      "         -1.2281e-02,  5.6778e-02,  2.3967e-03,  3.0459e-02, -3.5593e-02,\n",
      "          3.1351e-02, -6.2131e-02, -2.5901e-02,  7.5564e-05,  5.2441e-02,\n",
      "         -2.6442e-02, -5.3909e-02,  8.0691e-03, -3.2205e-02,  9.2896e-03,\n",
      "          2.2339e-02,  3.2690e-02,  1.0251e-02, -3.9217e-03, -5.1329e-03,\n",
      "          7.3495e-03,  1.9434e-02,  1.9962e-03,  3.2594e-03, -5.4208e-03,\n",
      "          1.4308e-02, -3.9210e-03, -1.1612e-03, -1.2789e-02, -3.1666e-02,\n",
      "          7.5395e-03,  1.6826e-02, -3.1947e-03,  4.1907e-02, -3.5878e-02,\n",
      "          2.9818e-02,  4.4594e-02,  1.1634e-02,  3.7468e-02, -1.9270e-02,\n",
      "         -2.2956e-04, -3.2349e-02,  3.6285e-02,  3.6508e-02,  2.1528e-02,\n",
      "         -1.1092e-03,  6.2147e-03, -3.6730e-02, -2.7868e-02, -1.5021e-02,\n",
      "          2.0409e-02,  3.0785e-02,  1.1168e-02,  1.8051e-02, -1.9116e-02,\n",
      "         -2.3738e-02,  1.5286e-02,  2.7573e-03,  3.1155e-02,  1.0435e-02,\n",
      "         -3.0481e-04, -1.5437e-02,  2.8709e-02,  1.1094e-02, -3.5541e-03,\n",
      "         -8.0053e-03,  1.3456e-02,  2.6499e-02, -8.5900e-03, -2.2880e-02,\n",
      "         -1.3348e-02,  2.1122e-02, -4.2278e-04,  2.7745e-03, -5.3217e-02,\n",
      "          3.6550e-02,  4.9760e-02, -9.0855e-03, -1.4019e-02,  5.8669e-03,\n",
      "          4.9687e-02, -4.5479e-03, -2.5512e-02,  1.2979e-02,  1.7501e-02,\n",
      "         -3.8346e-02, -1.6158e-02, -3.7856e-02,  9.8392e-04, -4.8914e-02,\n",
      "          8.3243e-02, -5.1973e-03,  4.3425e-04,  1.3386e-02,  5.4545e-02,\n",
      "          5.5199e-02,  3.2670e-02, -1.7495e-02, -4.4213e-02,  7.4326e-02,\n",
      "         -5.1928e-02, -2.0007e-02,  2.3022e-02, -8.3535e-04, -9.3878e-03,\n",
      "          2.2819e-02,  1.7871e-02, -1.7393e-02, -1.2637e-02, -3.0190e-02,\n",
      "         -1.8802e-02,  1.3258e-02, -1.3111e-02,  7.3686e-03,  1.9001e-02,\n",
      "          1.7078e-02, -4.2544e-02, -1.4758e-02, -2.2832e-02,  2.7096e-02,\n",
      "          1.3056e-02,  3.8937e-02,  4.4103e-02, -2.2121e-02,  4.4357e-02,\n",
      "          1.1432e-02,  1.6611e-02,  1.5824e-02,  3.0996e-02, -6.7667e-02,\n",
      "         -9.4735e-03, -1.0631e-02, -9.3696e-03, -3.3999e-02, -2.8460e-02,\n",
      "          1.0176e-02,  3.3556e-02, -1.8174e-04,  2.6564e-02, -2.7167e-02,\n",
      "         -2.1564e-02, -1.2591e-02, -3.9267e-02, -4.4020e-02,  2.3033e-02,\n",
      "         -1.6299e-03,  6.5613e-03,  1.3575e-02, -2.5319e-02, -5.3366e-02,\n",
      "          4.6414e-02, -1.2179e-02,  2.6734e-02,  2.6646e-02,  1.1998e-02,\n",
      "          1.2913e-02,  2.5066e-02, -1.6292e-02,  8.3347e-03, -1.0203e-03,\n",
      "          2.3663e-02,  1.3347e-02,  1.3796e-02, -3.2251e-02, -5.2066e-03,\n",
      "         -1.2387e-02, -1.5563e-02,  3.4762e-02,  3.8002e-02, -8.7734e-03,\n",
      "         -4.1993e-02,  3.9894e-02,  1.0836e-02,  2.6852e-03,  2.6729e-02,\n",
      "         -4.6852e-02, -6.3502e-03,  2.0322e-02,  2.6033e-02,  1.8447e-02,\n",
      "         -4.1665e-03,  7.6839e-03, -1.7130e-02, -4.9466e-02, -5.0443e-03,\n",
      "          1.3301e-02,  1.4828e-02,  2.7555e-02, -1.3147e-02, -3.3058e-02,\n",
      "         -2.0615e-02,  2.9799e-02, -2.5856e-02, -2.6310e-02, -5.7939e-03,\n",
      "         -4.3107e-02, -1.3879e-03, -2.5696e-02, -2.9173e-04, -1.5938e-02,\n",
      "         -3.1205e-02, -3.3946e-02,  4.2544e-02,  2.8253e-02, -2.0084e-02,\n",
      "         -1.4750e-02,  1.0215e-03,  3.7763e-02, -1.5892e-02, -1.4927e-02,\n",
      "         -4.5753e-04,  3.5813e-02,  7.2324e-03,  3.1163e-02, -1.5851e-02,\n",
      "          1.2048e-02,  8.9720e-04, -2.3778e-02, -2.5159e-02, -1.5979e-02,\n",
      "          2.5247e-02,  5.8848e-02,  9.4155e-03, -3.3857e-02,  3.7962e-02,\n",
      "         -2.3317e-02, -7.0283e-02, -5.6303e-03, -1.0210e-02, -1.8395e-02,\n",
      "          2.0416e-02, -1.2142e-02, -5.3147e-02, -1.5814e-02,  5.7894e-03,\n",
      "         -1.2541e-02, -1.5063e-02, -3.4586e-02, -1.1210e-03, -1.9965e-03,\n",
      "         -1.7188e-02, -2.1823e-02,  9.7076e-03, -1.6895e-02, -5.0767e-02,\n",
      "         -6.6052e-02,  2.5754e-02, -4.2631e-02, -3.9320e-02, -3.1593e-02,\n",
      "          5.0875e-02,  2.9560e-02,  1.0365e-03,  2.1591e-03, -2.2340e-02,\n",
      "         -5.4588e-02, -3.6021e-02, -1.4014e-02,  2.3800e-02,  3.3046e-02,\n",
      "         -1.4930e-02, -3.3864e-02,  1.1117e-02, -1.8087e-02,  9.1082e-03,\n",
      "          5.9249e-03,  2.4280e-02,  2.2293e-02,  4.7797e-03, -7.8813e-03]],\n",
      "       grad_fn=<WarnNotImplemented>)\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
