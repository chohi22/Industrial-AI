{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-05T13:41:39.718143Z",
     "start_time": "2025-06-05T13:41:37.075705Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch.nn.utils import prune\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"bert-base-multilingual-cased\",\n",
    "    do_lower_case=False\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chohi/project/ai/CapstonProject/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/chohi/project/ai/CapstonProject/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/chohi/project/ai/CapstonProject/.venv/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/chohi/project/ai/CapstonProject/.venv/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "W0605 22:41:39.280919 16912 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "/Users/chohi/project/ai/CapstonProject/.venv/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/chohi/project/ai/CapstonProject/.venv/lib/python3.9/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T13:43:44.377115Z",
     "start_time": "2025-06-05T13:43:39.145125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"bert-base-multilingual-cased\",\n",
    "    num_labels=2\n",
    ")\n",
    "model.load_state_dict(torch.load(\"../models/BertForSequenceClassification.pt\"))\n",
    "\n",
    "print(\"가지치기 적용 전:\")\n",
    "print(model.bert.encoder.layer[0].attention.self.key.weight)\n",
    "\n",
    "parameters = [\n",
    "    (model.bert.embeddings.word_embeddings, \"weight\"),\n",
    "    (model.bert.encoder.layer[0].attention.self.key, \"weight\"),\n",
    "    (model.bert.encoder.layer[1].attention.self.key, \"weight\"),\n",
    "    (model.bert.encoder.layer[2].attention.self.key, \"weight\"),\n",
    "]\n",
    "\n",
    "prune.global_unstructured(\n",
    "    parameters=parameters,\n",
    "    pruning_method=prune.L1Unstructured,\n",
    "    amount=0.2,\n",
    ")\n",
    "\n",
    "print(\"가지치기 적용 후:\")\n",
    "print(model.bert.encoder.layer[0].attention.self.key.weight)\n"
   ],
   "id": "381a4a9c159f9908",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가지치기 적용 전:\n",
      "Parameter containing:\n",
      "tensor([[-0.0254, -0.0597, -0.0390,  ...,  0.0077, -0.0269, -0.0045],\n",
      "        [ 0.0423,  0.0563,  0.0046,  ..., -0.0041,  0.0205,  0.0166],\n",
      "        [ 0.0156, -0.0439, -0.0090,  ..., -0.0118, -0.0885, -0.0516],\n",
      "        ...,\n",
      "        [-0.0313, -0.0221,  0.0341,  ..., -0.0011,  0.0103,  0.0087],\n",
      "        [-0.0755, -0.0749, -0.0065,  ..., -0.0131, -0.0329, -0.0984],\n",
      "        [ 0.0160, -0.0426, -0.0062,  ...,  0.0445, -0.0182,  0.0413]],\n",
      "       requires_grad=True)\n",
      "가지치기 적용 후:\n",
      "tensor([[-0.0254, -0.0597, -0.0390,  ...,  0.0000, -0.0269, -0.0000],\n",
      "        [ 0.0423,  0.0563,  0.0000,  ..., -0.0000,  0.0205,  0.0166],\n",
      "        [ 0.0156, -0.0439, -0.0000,  ..., -0.0118, -0.0885, -0.0516],\n",
      "        ...,\n",
      "        [-0.0313, -0.0221,  0.0341,  ..., -0.0000,  0.0000,  0.0000],\n",
      "        [-0.0755, -0.0749, -0.0000,  ..., -0.0131, -0.0329, -0.0984],\n",
      "        [ 0.0160, -0.0426, -0.0000,  ...,  0.0445, -0.0182,  0.0413]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
